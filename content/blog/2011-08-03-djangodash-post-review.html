{% extends '_post.html' %}

{% hyde
    title: Отчет об участие в DjangoDash
    created: 2011-08-03
    published: True
    categories: Python, Django, Open Source
    display_in_list: True
    snip: "[Django Dash](http://djangodash.com/) это небольшое соревнование для django-программистов-фанатиков суть которого сводится к реализации небольшого проекта в течении двух выходных дней. Точнее двух суток. Т.е. в абсолютно сумасшедшем режиме. В этом году я учавствовал с коллегой [Юрой](http://twitter.com/#!/ogiyenko) и мы пытались сделать сервер для мониторинга [gearman](http://gearman.org/) очередей (очень гиковская задумка). О том как все это прошло и чем завершилось, see below."
%}

{% block article %}

### Intro

В первую очередь хочу сказать огромное спасибо компании [Grammarly](http://www.grammarly.com/), которая в этом году "приютила" 3 киевские команды. Большое спасибо за очаровательный уютный офис, изумительно вкусные обеды и хорошую компанию таких же фанатиков как мы :)!.

### Что задумывалось нами задумывалось изначально?

Итак, нашей идей было создать приложение Gearoscope, суть которого сводилась к мониторингу [Gearman](http://gearman.org/) серверов на удаленных машинах: проверка состояний очередей и отслеживание процессов, которые занимаются выполнением задач из этих очередей. Задумка достаточно дерзкая, но исключительно полезная. У меня в проекте, который я делаю на работе (делал), одна gearman-нода обслживает 7 очередей и около 200.000 тасков в них за сутки. И это достаточно простая ситуация, можно все контролировать вручную, хотя "телодвижений" для этого уже приходится совершать очень и очень немало. Если же взять кластер по побольше, то там и подавно можно потерятся.

Как разработчику, или администратору системы, мне интересны следующие вещи:

- какие у меня есть gearman node-ы и доступны ли они в данный момент

- какие очереди "висят" в памяти, сколько там задач сейчас и какая динамика наполнения (задачи "прибывают" или "убывают" - это важно для принятия решения о небходимости увеличения workers capacity)

- что творится с worker-ами - процессами, которые эти задачи выполняют: сколько их, на каких машинах они крутятся, сколько памяти и CPU используют и т.д.

Помимо чисто мониторинговых задач позже сюда добавились требования:

- поднять новую ноду на удаленной машине

- запускать и перезапускать воркеры (как в ручном режиме, так и по автоматизированным сигналам)

- читать логи мониторинг системы и воркеров

- другое

Естественные требования к реализации: удобная админка для управления все этим делом, наглядный и юзабельный dashboard, позволяющий быстро охватить взглядом довольно большой объем информации, легкое разворачивание системы на существующем кластере, непритязательность к системный ресурсам для обеспечения работы самой мониторинг системы.

Задумка в реализации была основана на почти классических идеях организации мониторинг систем:

1. Монитор-сервер и визуализатор данных разделены не только идеологически, но и программно. Т.е. один процесс пишет все происходящее в логи, другой это логи читает, анализирует и визуализирует.

2. Монитор-сервер должен быть один, никакого дополнительного программного обеспечения не нужно устанавливать на каждый сервер в кластере. Прототип такой штуки у меня уже был и использовался в рабочем проекте. Для того, чтобы не нарушать условия соревнования, но и не  писать заново то, что уже есть, я перепил прототип и буквально за день до начала соревнования выложил фрейм как открытый проект [Sonar](https://github.com/kachayev/Sonar). В его основу положена мультиагентная архитектура, которая дает возможность выполнять различиные действия переодически в thread-ах или пулах thread-ов, забирая задачи из синхронизируемой очереди. Мини-фреймворк устанавливается через pip и имеет широкие возможности конфигурирования и "встраивания" в основной loop "сторонних" агентов.

3. Управление процессами достаточно сложная задумка, поэтому было решено использовать [supervisor](http://supervisord.org/) для запуска под ним воркеров. Это не только удобный способ внешней демонизации, но и XML-RPC интерфейс для получения детализированной информации о статусе процессов, а также удаленном их старте/рестарте/остановки.

4. Чего не умеет supervisor, так это отдавать инфу об использовании mem, cpu. Для того, чтобы закрыть этот пробел решили на локальной машине использовать библиотеку [psutil](http://code.google.com/p/psutil/), а для работы на удаленных - [Fabric](http://docs.fabfile.org/en/1.2.0/index.html) + `ps aux` + немного уличной магии.

5. Async I/O. В крупной кластере, монитор-сервер может получать большое количество информации. Чтобы постоянно не дергать лог, пытаясь в него что-то писать, было решено писать данные в memory buffer, и уже его переодически дампать в файл "большим" куском.

6. Визуализатор делится на две части: dashboard с графиками и HTML5 версткой (спасибо Юре) делающий ajax запросы на log analyzer, Django админка для управления всеми объектами в приложении (спасибо мне).

### Как все пошло

Об ошибках проектирования, потраченном времени на деплоймент, моих коммитах в два проекта сразу.





### Что получилось по итогам двух дней (точнее двух суток) работы?

Огромное количество впечатлений, эмоций и драйва. И неплохой костяк для создания приложения. Не могу назвать это приложением, потому что до production-mode ему еще очень далеко, не только с технической точки зрения, но и с точки зрения полезности/удобности и других плюшек, за которые такие приложения ценят. Смело могу сделать вывод, что иногда очень полезно работать в таком режиме, как минимум для встряски мозга, который очень быстро привыкает работать в "штатном" режиме и не напрягатся дольше 8ми рабочих часов в день.

Также могу констатировать, что наша команда попала в первую десятку рейтинга по количеству коммитов, а я занял почетное 3е место в **Individual commit leaderboard** с показателем в 147 коммитов за 2 дня. Спорное, но все же достижение :)

### Следующий Django Dash

Если Djagno Dash будет проводится в следующем году, то обязательно поучаствуем, но с некоторыми "правками":

- менее гиковский проект, менее технически сложный и более близкий к "конечному" потребителю. Дай бог с идеями проблем не должно быть

- проектирование нужно проводить до самых тонких мелочей **до начала** соревнования, потом на них просто не хватает времени

- каким бы безумием это не казалось, но нужен какой-то Continius Integration, или его подобие хотя бы. Ни в коем случае не допустимо выкатыватся на прод-сервер за 2-3 часа до окончания соревнований, потому что этот процесс всега стыкуется с чем-то непредвиденным. А начиная с первого "удачного" деплоймента нужно быть всегда уверенным, что после внесенных изменений можно в одну команду вернутся к предыдущей версии развертки, чтобы какая-нибудь критичная бага не застала в самый неприятный момент "финального свистка"

### Планы по развитию проекта



{% endblock %}

